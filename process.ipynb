{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_20568\\99135878.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load RoBERTa pre-trained model and tokenizer for sentiment analysis\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute sentiment scores using RoBERTa\n",
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    return {\n",
    "        'positive': scores[2],\n",
    "        'neutral': scores[1],\n",
    "        'negative': scores[0]\n",
    "    }\n",
    "\n",
    "# Function to process an Excel file and calculate sentiment percentages\n",
    "def process_excel_file(file_path):\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Check if 'Comments' column exists\n",
    "    if 'Comments' not in df.columns:\n",
    "        raise ValueError(f\"'Comments' column not found in {file_path}\")\n",
    "    \n",
    "    # Drop rows with missing values in the 'Comments' column\n",
    "    comments = df['Comments'].dropna().tolist()\n",
    "    \n",
    "    # Initialize counters for sentiments\n",
    "    total_comments = len(comments)\n",
    "    pos_count, neu_count, neg_count = 0, 0, 0\n",
    "    \n",
    "    # Process each comment and calculate sentiment\n",
    "    for comment in tqdm(comments, desc=f\"Processing {file_path}\"):\n",
    "        try:\n",
    "            sentiment_scores = polarity_scores_roberta(comment)\n",
    "            if sentiment_scores['positive'] > sentiment_scores['neutral'] and sentiment_scores['positive'] > sentiment_scores['negative']:\n",
    "                pos_count += 1\n",
    "            elif sentiment_scores['neutral'] > sentiment_scores['positive'] and sentiment_scores['neutral'] > sentiment_scores['negative']:\n",
    "                neu_count += 1\n",
    "            else:\n",
    "                neg_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing comment: {e}\")\n",
    "    \n",
    "    # Calculate sentiment percentages\n",
    "    pos_percentage = (pos_count / total_comments) * 100\n",
    "    neu_percentage = (neu_count / total_comments) * 100\n",
    "    neg_percentage = (neg_count / total_comments) * 100\n",
    "    \n",
    "    return {\n",
    "        'positive': pos_percentage,\n",
    "        'neutral': neu_percentage,\n",
    "        'negative': neg_percentage\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing anura_cleaned.xlsx:   7%|▋         | 36/552 [00:03<00:33, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing comment: The expanded size of the tensor (787) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 787].  Tensor sizes: [1, 514]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing anura_cleaned.xlsx: 100%|██████████| 552/552 [00:40<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment percentages for anura_cleaned.xlsx:\n",
      "Positive: 51.81%\n",
      "Neutral: 41.85%\n",
      "Negative: 6.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing namal_cleaned.xlsx: 100%|██████████| 1663/1663 [01:48<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment percentages for namal_cleaned.xlsx:\n",
      "Positive: 15.51%\n",
      "Neutral: 79.68%\n",
      "Negative: 4.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Ranil_cleaned.xlsx: 100%|██████████| 864/864 [01:04<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment percentages for Ranil_cleaned.xlsx:\n",
      "Positive: 44.56%\n",
      "Neutral: 47.69%\n",
      "Negative: 7.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sajith_cleaned.xlsx:  94%|█████████▍| 372/395 [00:26<00:01, 17.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing comment: The expanded size of the tensor (896) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 896].  Tensor sizes: [1, 514]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sajith_cleaned.xlsx: 100%|██████████| 395/395 [00:28<00:00, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment percentages for sajith_cleaned.xlsx:\n",
      "Positive: 21.27%\n",
      "Neutral: 64.56%\n",
      "Negative: 13.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# List of Excel files to process\n",
    "files = ['anura_cleaned.xlsx', 'namal_cleaned.xlsx', 'Ranil_cleaned.xlsx', 'sajith_cleaned.xlsx']\n",
    "\n",
    "# Process each file and display results\n",
    "for file in files:\n",
    "    try:\n",
    "        sentiment_percentages = process_excel_file(file)\n",
    "        print(f\"\\nSentiment percentages for {file}:\")\n",
    "        print(f\"Positive: {sentiment_percentages['positive']:.2f}%\")\n",
    "        print(f\"Neutral: {sentiment_percentages['neutral']:.2f}%\")\n",
    "        print(f\"Negative: {sentiment_percentages['negative']:.2f}%\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
